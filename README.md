---
# ğŸ§  AI Knowledge Miner  
**A Retrieval-Augmented Generation (RAG) system built with Node.js, TypeScript, OpenAI & Pinecone**

> â€œTeach your AI to *remember*, *search*, and *reason*.â€  

---

## ğŸš€ Overview  

**AI Knowledge Miner** is a lightweight Retrieval-Augmented Generation (RAG) pipeline.  
It combines **vector search** (Pinecone) with **OpenAI embeddings & generation**, allowing you to ask questions about your own data â€” with context-aware, memory-backed responses.  

This repo contains two parts:
- ğŸ§© **Backend** â€“ Handles vector storage, embeddings, and queries.  
- ğŸ’» **CLI** â€“ Command-line interface for ingesting files & asking questions.  

---

## ğŸ§  What It Does  

1. **Embeds** your documents or text into vectors using OpenAIâ€™s `text-embedding-3-small` model.  
2. **Stores** those vectors in Pinecone (your external vector database).  
3. **Retrieves** the most relevant chunks when you ask a question.  
4. **Augments** GPT with those retrieved contexts for better, factual responses.  

Think of it like:

You â†’ (CLI) â†’ Question â†’ Embed â†’ Retrieve (Pinecone) â†“ Context + GPT â†’ Answer

---

## âš™ï¸ Tech Stack  

| Tool | Purpose |
|------|----------|
| **Node.js + TypeScript** | Core backend & CLI scripting |
| **OpenAI API** | Embeddings + LLM text generation |
| **Pinecone** | Vector database for semantic search |
| **Yargs** | CLI command parsing |
| **Dotenv** | Secure environment variable management |

---

## ğŸ§© Folder Structure

ai-knowledge-miner/ â”‚ â”œâ”€â”€ backend/ â”‚   â”œâ”€â”€ src/ â”‚   â”‚   â”œâ”€â”€ vector.ts      # Handles embedding + Pinecone upsert/query â”‚   â”‚   â”œâ”€â”€ qa.ts          # Handles Q&A logic and prompt composition â”‚   â”œâ”€â”€ tsconfig.json â”‚   â”œâ”€â”€ package.json â”‚ â”œâ”€â”€ cli/ â”‚   â”œâ”€â”€ src/ â”‚   â”‚   â””â”€â”€ index.ts       # CLI entry point (yargs setup) â”‚   â”œâ”€â”€ tsconfig.json â”‚   â”œâ”€â”€ package.json â”‚ â”œâ”€â”€ .env.example           # API keys and config template â””â”€â”€ README.md

---

## ğŸ”‘ Environment Variables  

Create a `.env` file in both **backend/** and **cli/** with:

OPENAI_API_KEY=your_openai_api_key PINECONE_API_KEY=your_pinecone_api_key PINECONE_ENVIRONMENT=your_pinecone_environment PINECONE_INDEX=ai-knowledge-index

---

## ğŸ§  Example Commands (CLI)

```bash
# Ingest all text files from a folder
npx ai-miner ingest ./notes

# Ask your data a question
npx ai-miner ask "What are the key ideas in file X?"

# Benchmark or test retrieval
npx ai-miner test


---

ğŸ’¡ How It Works (Simple Terms)

Embedding: turns text into numbers that capture meaning.

Vector DB (Pinecone): stores those number-representations efficiently.

Retrieval: when you ask something, it finds the closest matching meanings.

Generation: OpenAI uses those results to answer intelligently â€” with context awareness.



---

ğŸ§° Roadmap

[ ] Add local file caching

[ ] Support PDF & Markdown ingestion

[ ] Add chat session memory

[ ] Web dashboard (Next.js)

[ ] Deploy as an API service



---

ğŸ§‘â€ğŸ’» Author

 AdÃ© SopÃ© 




---

âš¡ Inspiration

This project is inspired by how RAG powers systems like ChatGPT Retrieval, Notion Q&A, and GitHub Copilot Chat â€” bringing memory and reasoning together.


---

ğŸª„ License

MIT Â© 2025
Use freely, build smarter.

---

